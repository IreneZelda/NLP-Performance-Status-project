{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450b4883",
   "metadata": {},
   "source": [
    "### 8.Evaluation regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "#load validation results\n",
    "val_class_results = pd.read_csv(r'.\\Results\\acsess_class_results_val.csv', sep = '\\t')\n",
    "#load test results\n",
    "test_class_results = pd.read_csv(r'.\\Results\\acsess_class_results_test.csv', sep = '\\t')\n",
    " \n",
    "\n",
    "### Change according to number of examples used during training\n",
    "k=0  #zero-shot\n",
    "#k=1 #one-shot\n",
    "#k=5 #few-shot\n",
    "\n",
    "val_class_results.columns = test_class_results.columns.str.replace('binary ', '', regex=False)\n",
    "test_class_results.columns = test_class_results.columns.str.replace('binary ', '', regex=False)\n",
    "val_class_results['Baseline all 0'] = len(val_class_results) * [0]\n",
    "val_class_results = val_class_results[val_class_results['relevance_manual'] == 1]\n",
    "test_class_results['Baseline all 0'] = len(test_class_results) * [0]\n",
    "test_class_results = test_class_results[test_class_results['relevance_manual'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6542096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(df, target_column, prediction_columns):\n",
    "    # Initialize a dictionary to store the results\n",
    "    results = {col: {'mae': [], 'mse': [], 'rmse': []} for col in prediction_columns}\n",
    "\n",
    "    # Loop over each fold and each prediction column\n",
    "    for fold in ['fold1', 'fold2', 'fold3', 'fold4', 'fold5']:\n",
    "        for col in prediction_columns:\n",
    "            # Filter the data for the current fold\n",
    "            fold_data = df[df['fold'] == fold]\n",
    "\n",
    "            if fold_data.empty:\n",
    "                continue\n",
    "\n",
    "            # Get the ground truth and predictions, ignoring NaN values\n",
    "            y_true = fold_data[target_column]\n",
    "            y_pred = fold_data[col].dropna()\n",
    "            y_true = y_true.loc[y_pred.index]\n",
    "\n",
    "            if y_true.empty or y_pred.empty:\n",
    "                continue\n",
    "\n",
    "            # Calculate MAE, MSE, and RMSE\n",
    "            mae = mean_absolute_error(y_true, y_pred)\n",
    "            mse = mean_squared_error(y_true, y_pred)\n",
    "            rmse = np.sqrt(mse)\n",
    "\n",
    "            # Append the scores to the results dictionary\n",
    "            results[col]['mae'].append(mae)\n",
    "            results[col]['mse'].append(mse)\n",
    "            results[col]['rmse'].append(rmse)\n",
    "\n",
    "    return results\n",
    "\n",
    "def generate_results_table(df, target_column, prediction_columns):\n",
    "    # Calculate metrics\n",
    "    results = calculate_metrics(df, target_column, prediction_columns)\n",
    "\n",
    "    # Calculate averages and standard deviations for each prediction column\n",
    "    mae_avg_list, mae_std_list = [], []\n",
    "    mse_avg_list, mse_std_list = [], []\n",
    "    rmse_avg_list, rmse_std_list = [], []\n",
    "\n",
    "    for col in prediction_columns:\n",
    "        if results[col]['mae']:\n",
    "            mae_avg = np.mean(results[col]['mae'])\n",
    "            mae_std = np.std(results[col]['mae'])\n",
    "        else:\n",
    "            mae_avg = np.nan\n",
    "            mae_std = np.nan\n",
    "        \n",
    "        if results[col]['mse']:\n",
    "            mse_avg = np.mean(results[col]['mse'])\n",
    "            mse_std = np.std(results[col]['mse'])\n",
    "        else:\n",
    "            mse_avg = np.nan\n",
    "            mse_std = np.nan\n",
    "        \n",
    "        if results[col]['rmse']:\n",
    "            rmse_avg = np.mean(results[col]['rmse'])\n",
    "            rmse_std = np.std(results[col]['rmse'])\n",
    "        else:\n",
    "            rmse_avg = np.nan\n",
    "            rmse_std = np.nan\n",
    "\n",
    "        mae_avg_list.append(mae_avg)\n",
    "        mae_std_list.append(mae_std)\n",
    "        mse_avg_list.append(mse_avg)\n",
    "        mse_std_list.append(mse_std)\n",
    "        rmse_avg_list.append(rmse_avg)\n",
    "        rmse_std_list.append(rmse_std)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    results_table = pd.DataFrame({\n",
    "        'Prediction Column': prediction_columns,\n",
    "        'MAE (Avg)': mae_avg_list,\n",
    "        'MAE (Std)': mae_std_list,\n",
    "        'MSE (Avg)': mse_avg_list,\n",
    "        'MSE (Std)': mse_std_list,\n",
    "        'RMSE (Avg)': rmse_avg_list,\n",
    "        'RMSE (Std)': rmse_std_list\n",
    "    })\n",
    "\n",
    "    return results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45fda7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `class_results` is your dataframe and it has a column 'fold' and a target column 'relevance_manual'\n",
    "target_column = 'relevance_manual'\n",
    "prediction_columns = [f'k={i}' for i in range(k)] \n",
    "results_table = generate_results_table(val_class_results, 'manual_sentence_labels', ['k=0', 'k=1', 'k=2','k=3','k=4', 'k=5', 'Baseline all 0'])\n",
    "print('Results regression task on validation set')\n",
    "print(results_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9bbb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `class_results` is your dataframe and it has a column 'fold' and a target column 'relevance_manual'\n",
    "target_column = 'relevance_manual'\n",
    "prediction_columns = [f'k={i}' for i in range(k)] \n",
    "results_table = generate_results_table(test_class_results, 'manual_sentence_labels', ['k=0', 'k=1', 'k=2','k=3','k=4', 'k=5', 'Baseline all 0'])\n",
    "print('Results regression task on test set')\n",
    "print(results_table.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyDRE",
   "language": "python",
   "name": "mydre"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

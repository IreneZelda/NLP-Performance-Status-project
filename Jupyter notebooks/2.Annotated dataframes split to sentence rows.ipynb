{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e74bda9d",
   "metadata": {},
   "source": [
    "# 2. Annotated dataframes split to sentence rows\n",
    "This notebook transforms the dataframes of step 1 into a dataframe in which each row corresponds to one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3680850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "##Assuming 3 rounds here, to be adjusted depending on your annotation rounds\n",
    "\n",
    "first_round = pd.read_csv(r'.\\Intermediate results\\first round.csv', sep = '\\t')\n",
    "second_round = pd.read_csv(r'.\\Intermediate results\\second round.csv', sep = '\\t')\n",
    "third_round = pd.read_csv(r'.\\Intermediate results\\third round.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383405cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select only useful columns--> to be changed for other datasets\n",
    "columns = ['annotator', 'censored', 'location', 'manual_sentence_labels', 'note_PS_manual', 'note_nr', 'previous_ann', 'pseudo_id', 'pseudonomised_text', 'relevance_PS_manual', 'relevance_manual', 'report_date', 'report_type', 'round', 'sentences', 'set', 'source_table', 'text_id']\n",
    "\n",
    "first_round_adjudicated = first_round_adjudicated[columns]\n",
    "second_round_adjudicated = second_round_adjudicated[columns]\n",
    "test_round_adjudicated = test_round_adjudicated[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e641eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely evaluate strings that look like Python lists\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        if isinstance(val, str):\n",
    "            # Replace 'nan' strings with 'None' first\n",
    "            val = val.replace('nan', 'None')\n",
    "            val = val.replace('np.float64(0.0)', '0')\n",
    "            val = val.replace('np.float64(1.0)', '1')\n",
    "            val = val.replace('np.float64(2.0)', '2')\n",
    "            val = val.replace('np.float64(3.0)', '3')\n",
    "            val = val.replace('np.float64(4.0)', '4')\n",
    "            val = val.replace('np.float64(5.0)', '5')\n",
    "            val = val.replace('np.float64(1.5)', '1.5')\n",
    "            # Safely evaluate the string as a Python literal\n",
    "            result = ast.literal_eval(val)\n",
    "            \n",
    "            # Convert None to np.nan and ensure numbers are integers\n",
    "            def convert_value(v):\n",
    "                if v is None:\n",
    "                    return np.nan\n",
    "                elif isinstance(v, (int, float,np.float64)) and not np.isnan(v):\n",
    "                    print(v)\n",
    "                    return int(v)\n",
    "                else:\n",
    "                    print(v)\n",
    "                    return v\n",
    "            \n",
    "            return [convert_value(v) for v in result]\n",
    "        return val\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        # Return the original value if evaluation fails\n",
    "        print(f\"Error evaluating {val}: {e}\")\n",
    "        return val\n",
    "\n",
    "# Function to apply safe_literal_eval to specified columns in a DataFrame\n",
    "def back_to_lists(df, columns_to_convert):\n",
    "    print(\"NEW DF\")\n",
    "    for col in columns_to_convert:\n",
    "        print(\"COLUMN:\", col)\n",
    "        df[col] = df[col].apply(safe_literal_eval)\n",
    "    return df\n",
    "\n",
    "# List of DataFrames\n",
    "dfs = [\n",
    "    first_round, \n",
    "    second_round, \n",
    "    test_round\n",
    "]\n",
    "\n",
    "# Columns you want to convert using safe_literal_eval\n",
    "columns_to_convert = ['manual_sentence_labels', 'relevance_manual', 'sentences']\n",
    "\n",
    "# Apply the back_to_lists function to each DataFrame in the list\n",
    "for i in range(len(dfs)):\n",
    "    dfs[i] = back_to_lists(dfs[i], columns_to_convert)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab83da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df = pd.concat([first_round, second_round, test_round])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ad5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Annotate sentences with Performance Status equal to 5, when they contain the sentence \"patient overleden\"\n",
    "\n",
    "print((end_df['sentences'][end_df['pseudonomised_text'].str.contains(\"patient overleden\")]).index)\n",
    "\n",
    "end_df.iloc[0, end_df.columns.get_loc('manual_sentence_labels')] = [5]\n",
    "end_df.iloc[0, end_df.columns.get_loc('note_PS_manual')] = 5\n",
    "end_df.iloc[0, end_df.columns.get_loc('relevance_PS_manual')] = 1\n",
    "end_df.iloc[0, end_df.columns.get_loc('relevance_manual')] = [1]\n",
    "#end_df.at[0, 'manual_sentence_labels'] = [5]\n",
    "#end_df['note_PS_manual'][0] = 5\n",
    "#end_df['relevance_PS_manual'][0] = 1\n",
    "#end_df['relevance_manual'][0] = [1]\n",
    "\n",
    "print(end_df[['manual_sentence_labels', 'note_PS_manual', 'relevance_PS_manual', 'relevance_manual']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3a52af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df = pd.DataFrame(columns = ['note_nr', 'sentence', 'manual_sentence_labels', 'relevance_manual', 'round', 'annotator', 'set'])\n",
    "\n",
    "for index, row in end_df.iterrows():\n",
    "\n",
    "    for i in range(len(row['sentences'])):\n",
    "        sentence = row['sentences'][i]\n",
    "        PS = row['manual_sentence_labels'][i]\n",
    "        relevance = row['relevance_manual'][i]\n",
    "        #sentences_df = sentences_df.append({'note_nr': row['note_nr'], 'sentence': sentence, 'manual_sentence_labels': PS, 'relevance_manual': relevance, 'round': row['round'], 'annotator': row['annotator'], 'set': row['set']}, ignore_index=True)\n",
    "        sentences_df=pd.concat([sentences_df,pd.DataFrame([{'note_nr': row['note_nr'], 'sentence': sentence, 'manual_sentence_labels': PS, 'relevance_manual': relevance, 'round': row['round'], 'annotator': row['annotator'], 'set': row['set']}])],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c445438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_val = sentences_df[sentences_df['set'] == 'val']\n",
    "sentences_test = sentences_df[sentences_df['set'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe3af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"VAL:\")\n",
    "print(sentences_val['manual_sentence_labels'].value_counts(dropna=False))\n",
    "print(len(sentences_val))\n",
    "print(\"TEST:\")\n",
    "print(sentences_test['manual_sentence_labels'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c74395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_val.to_csv(r'./Intermediate results/sentences_val.csv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa3132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences_test.to_csv(r'./Intermediate results/sentences_test.csv', sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyDRE",
   "language": "python",
   "name": "mydre"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
